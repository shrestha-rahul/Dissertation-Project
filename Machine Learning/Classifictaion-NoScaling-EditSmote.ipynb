{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import date\n",
    "import pandas_datareader as data\n",
    "from pandas_datareader import *\n",
    "import math\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "#Model\n",
    "#Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping Dataset from Yahoo Finance using yfinance\n",
    "#Getting data for the Apple Stock\n",
    "aapl = yf.Ticker(\"AAPL\")\n",
    "\n",
    "# Apple Company Information\n",
    "# aapl.info\n",
    "\n",
    "# Apple's Historical Stock Prices (10 Year Period)\n",
    "aapl.dataset = aapl.history(period=\"10y\")\n",
    "\n",
    "#YFinance Bug- Dropped columns appears after being dropped so copying into new dataset\n",
    "dataset = aapl.dataset [['Open', 'Close', 'High', 'Low','Volume']].copy()\n",
    "\n",
    "# Calculating %K and %D\n",
    "dataset['14-high'] = dataset['High'].rolling(14).max()\n",
    "dataset['14-low'] = dataset['Low'].rolling(14).min()\n",
    "dataset['%K'] = (dataset['Close'] - dataset['14-low'])*100/(dataset['14-high'] - dataset['14-low'])\n",
    "dataset['%D'] = dataset['%K'].rolling(3).mean()\n",
    "\n",
    "#Dropping 14-HIGH AND 14-LOW COLUMNS\n",
    "dataset.drop(['14-high', '14-low'], axis = 1, inplace=True)\n",
    "\n",
    "def categorise_so(row):  \n",
    "    if row['%K'] <= 20 and row['%D'] <= 20:\n",
    "        return 'Buy'\n",
    "    elif row['%K'] >= 80 and  row['%D']>= 80:\n",
    "        return 'Sell'\n",
    "    else:\n",
    "        return 'Hold'\n",
    "\n",
    "    \n",
    "   \n",
    "dataset['SO Indicator'] = dataset.apply(lambda row: categorise_so(row), axis=1)\n",
    "\n",
    "\n",
    "delta = dataset['Close'].diff()\n",
    "up = delta.clip(lower=0)\n",
    "down = -1*delta.clip(upper=0)\n",
    "ema_up = up.ewm(com=13, adjust=False).mean()\n",
    "ema_down = down.ewm(com=13, adjust=False).mean()\n",
    "rs = ema_up/ema_down\n",
    "dataset['RSI'] = 100 - (100/(1 + rs))\n",
    "\n",
    "# Adding Buy/Sell Signals from RSI Indicator\n",
    "def categorise_rsi(row):  \n",
    "    if row['RSI'] <= 30:\n",
    "        return 'Buy'\n",
    "    elif row['RSI'] >= 70:\n",
    "        return 'Sell'\n",
    "    else:\n",
    "        return 'Hold'\n",
    "  \n",
    "dataset['RSI Indicator'] = dataset.apply(lambda row: categorise_rsi(row), axis=1)\n",
    "\n",
    "def get_sma(prices, rate):\n",
    "    return prices.rolling(rate).mean()\n",
    "\n",
    "def get_bollinger_bands(prices, rate=20):\n",
    "    # SMA for 20 Days (Middle Band)\n",
    "    sma = get_sma(prices, rate)\n",
    "    std = prices.rolling(rate).std()\n",
    "\n",
    "    # Calculating Upper Band\n",
    "    bollinger_upper = sma + (std * 2 )\n",
    "\n",
    "    # Calculate Lower Band\n",
    "    bollinger_lower = sma - (std * 2 )\n",
    "\n",
    "    #Middle Band\n",
    "    bollinger_middle = sma\n",
    "    return bollinger_upper, bollinger_lower, bollinger_middle\n",
    "\n",
    "\n",
    "closing_prices = dataset['Close']\n",
    "\n",
    "\n",
    "bollinger_upper, bollinger_lower, bollinger_middle = get_bollinger_bands(closing_prices)\n",
    "\n",
    "#Adding Bollinger Bands to the Dataset\n",
    "dataset['Bollinger_Upper'] = bollinger_upper\n",
    "dataset['Bollinger_Lower'] = bollinger_lower\n",
    "\n",
    "\n",
    "# Adding Buy/Sell Signals from Bollinger Bands Indicator\n",
    "def categorise_bollinger(row):  \n",
    "    if row['Close'] < row['Bollinger_Lower']:\n",
    "        return 'Buy'\n",
    "    elif row['Close'] > row['Bollinger_Upper']:\n",
    "        return 'Sell'\n",
    "    else:\n",
    "        return 'Hold'\n",
    "    \n",
    "   \n",
    "dataset['Bollinger Indicator'] = dataset.apply(lambda row: categorise_bollinger(row), axis=1)\n",
    "\n",
    "# Calculating the MACD Line and the Signal Line\n",
    "ema12 = dataset['Close'].ewm(span=12, adjust=False).mean()\n",
    "ema26 = dataset['Close'].ewm(span=26, adjust=False).mean()\n",
    "macd = ema12 - ema26\n",
    "signal = macd.ewm(span=9, adjust=False).mean()\n",
    "\n",
    "\n",
    "#Appeding the MACD and Signal Data to Dataset\n",
    "dataset['MACD'] = macd\n",
    "dataset['Signal'] = signal\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recommender Based on the three indicators\n",
    "def recommender(row): \n",
    "    # If All Share the Same Signal OutPut That Signal (Buy)\n",
    "    if row['RSI Indicator'] == \"Buy\" and row['SO Indicator'] == 'Buy' and  row['Bollinger Indicator'] == 'Buy':\n",
    "        return 'Buy'\n",
    "     # If Any 2 Indicators Share the Same Signal Output That Signal (buy)\n",
    "    elif row['RSI Indicator'] == 'Buy' and row['SO Indicator'] == 'Buy':\n",
    "        return 'Buy'\n",
    "    elif row['RSI Indicator'] == 'Buy' and row['Bollinger Indicator'] == 'Buy':\n",
    "        return 'Buy'\n",
    "    elif row['SO Indicator'] == 'Buy' and row['Bollinger Indicator'] == 'Buy':\n",
    "        return 'Buy'   \n",
    "    # If All Share the Same Signal Output That Signal (Sell)\n",
    "    elif row['RSI Indicator'] == 'Sell' and row['SO Indicator'] == 'Sell' and  row['Bollinger Indicator'] == 'Sell':\n",
    "        return 'Sell'\n",
    "    # If Any 2 Indicators Share the Same Signal Output That Signal (Sell)\n",
    "    elif row['RSI Indicator'] == 'Sell' and row['SO Indicator'] == 'Sell':\n",
    "        return 'Sell'\n",
    "    elif row['RSI Indicator'] == 'Sell' and row['Bollinger Indicator'] == 'Sell':\n",
    "        return 'Sell'\n",
    "    elif row['SO Indicator'] == 'Sell' and row['Bollinger Indicator'] == 'Sell':\n",
    "        return 'Sell'    \n",
    "    # If All Share the Same Signal OutPut That Signal (Hold)\n",
    "    elif row['RSI Indicator'] == 'Hold' and row['SO Indicator'] == 'Hold' and  row['Bollinger Indicator'] == 'Hold':\n",
    "        return 'Hold'\n",
    "    # If Any 2 Indicators Share the Same Signal Output That Signal (Hold)\n",
    "    elif row['RSI Indicator'] == 'Hold' and row['SO Indicator'] == 'Hold':\n",
    "        return 'Hold'\n",
    "    elif row['RSI Indicator'] == 'Hold' and row['Bollinger Indicator'] == 'Hold':\n",
    "        return 'Hold'\n",
    "    elif row['SO Indicator'] == 'Hold' and row['Bollinger Indicator'] == 'Hold':\n",
    "        return 'Hold'      \n",
    "    else:\n",
    "        return 'Unclassed'\n",
    "\n",
    "dataset['Recommender'] = dataset.apply(lambda row: recommender(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.drop(['RSI Indicator', 'SO Indicator',  'Bollinger Indicator'], axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 2518 entries, 2012-04-30 to 2022-04-29\n",
      "Data columns (total 13 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   Open             2518 non-null   float64\n",
      " 1   Close            2518 non-null   float64\n",
      " 2   High             2518 non-null   float64\n",
      " 3   Low              2518 non-null   float64\n",
      " 4   Volume           2518 non-null   int64  \n",
      " 5   %K               2505 non-null   float64\n",
      " 6   %D               2503 non-null   float64\n",
      " 7   RSI              2517 non-null   float64\n",
      " 8   Bollinger_Upper  2499 non-null   float64\n",
      " 9   Bollinger_Lower  2499 non-null   float64\n",
      " 10  MACD             2518 non-null   float64\n",
      " 11  Signal           2518 non-null   float64\n",
      " 12  Recommender      2518 non-null   object \n",
      "dtypes: float64(11), int64(1), object(1)\n",
      "memory usage: 275.4+ KB\n"
     ]
    }
   ],
   "source": [
    "#Information regarding the dataset\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Open               0\n",
       "Close              0\n",
       "High               0\n",
       "Low                0\n",
       "Volume             0\n",
       "%K                 0\n",
       "%D                 0\n",
       "RSI                0\n",
       "Bollinger_Upper    0\n",
       "Bollinger_Lower    0\n",
       "MACD               0\n",
       "Signal             0\n",
       "Recommender        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dropping Null Values\n",
    "dataset = dataset.dropna()\n",
    "dataset.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 2499 entries, 2012-05-25 to 2022-04-29\n",
      "Data columns (total 13 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   Open             2499 non-null   float64\n",
      " 1   Close            2499 non-null   float64\n",
      " 2   High             2499 non-null   float64\n",
      " 3   Low              2499 non-null   float64\n",
      " 4   Volume           2499 non-null   int64  \n",
      " 5   %K               2499 non-null   float64\n",
      " 6   %D               2499 non-null   float64\n",
      " 7   RSI              2499 non-null   float64\n",
      " 8   Bollinger_Upper  2499 non-null   float64\n",
      " 9   Bollinger_Lower  2499 non-null   float64\n",
      " 10  MACD             2499 non-null   float64\n",
      " 11  Signal           2499 non-null   float64\n",
      " 12  Recommender      2499 non-null   int64  \n",
      "dtypes: float64(11), int64(2)\n",
      "memory usage: 273.3 KB\n"
     ]
    }
   ],
   "source": [
    "# #Encode Categorical Variables\n",
    "signal_dict = {'Hold': 0, 'Sell': 1, 'Buy': 2}\n",
    "\n",
    "dataset['Recommender'] = dataset['Recommender'].map(signal_dict)\n",
    "\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=dataset.iloc[:,12:13]\n",
    "X=dataset.iloc[:,0:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Volume</th>\n",
       "      <th>%K</th>\n",
       "      <th>%D</th>\n",
       "      <th>RSI</th>\n",
       "      <th>Bollinger_Upper</th>\n",
       "      <th>Bollinger_Lower</th>\n",
       "      <th>MACD</th>\n",
       "      <th>Signal</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-05-25</th>\n",
       "      <td>17.265854</td>\n",
       "      <td>17.195517</td>\n",
       "      <td>17.304387</td>\n",
       "      <td>17.078696</td>\n",
       "      <td>328507200</td>\n",
       "      <td>73.840536</td>\n",
       "      <td>79.791649</td>\n",
       "      <td>44.076190</td>\n",
       "      <td>18.186332</td>\n",
       "      <td>16.302006</td>\n",
       "      <td>-0.172952</td>\n",
       "      <td>-0.215631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-05-29</th>\n",
       "      <td>17.458816</td>\n",
       "      <td>17.500711</td>\n",
       "      <td>17.553618</td>\n",
       "      <td>17.287868</td>\n",
       "      <td>380508800</td>\n",
       "      <td>92.212800</td>\n",
       "      <td>81.823858</td>\n",
       "      <td>50.208127</td>\n",
       "      <td>18.132156</td>\n",
       "      <td>16.320371</td>\n",
       "      <td>-0.130183</td>\n",
       "      <td>-0.198541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-05-30</th>\n",
       "      <td>17.406832</td>\n",
       "      <td>17.711727</td>\n",
       "      <td>17.736804</td>\n",
       "      <td>17.326098</td>\n",
       "      <td>529429600</td>\n",
       "      <td>98.581578</td>\n",
       "      <td>88.211638</td>\n",
       "      <td>53.966478</td>\n",
       "      <td>18.116348</td>\n",
       "      <td>16.327127</td>\n",
       "      <td>-0.078357</td>\n",
       "      <td>-0.174504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-05-31</th>\n",
       "      <td>17.759736</td>\n",
       "      <td>17.667688</td>\n",
       "      <td>17.782979</td>\n",
       "      <td>17.475944</td>\n",
       "      <td>491674400</td>\n",
       "      <td>93.644704</td>\n",
       "      <td>94.813027</td>\n",
       "      <td>53.066230</td>\n",
       "      <td>18.068708</td>\n",
       "      <td>16.349539</td>\n",
       "      <td>-0.040374</td>\n",
       "      <td>-0.147678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-06-01</th>\n",
       "      <td>17.405605</td>\n",
       "      <td>17.155756</td>\n",
       "      <td>17.512334</td>\n",
       "      <td>17.141384</td>\n",
       "      <td>520987600</td>\n",
       "      <td>65.424760</td>\n",
       "      <td>85.883681</td>\n",
       "      <td>43.898707</td>\n",
       "      <td>17.991827</td>\n",
       "      <td>16.362718</td>\n",
       "      <td>-0.050992</td>\n",
       "      <td>-0.128341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-25</th>\n",
       "      <td>161.119995</td>\n",
       "      <td>162.880005</td>\n",
       "      <td>163.169998</td>\n",
       "      <td>158.460007</td>\n",
       "      <td>96046400</td>\n",
       "      <td>22.278221</td>\n",
       "      <td>14.362295</td>\n",
       "      <td>41.927588</td>\n",
       "      <td>180.981810</td>\n",
       "      <td>159.888189</td>\n",
       "      <td>-1.131611</td>\n",
       "      <td>-0.008625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-26</th>\n",
       "      <td>162.250000</td>\n",
       "      <td>156.800003</td>\n",
       "      <td>162.339996</td>\n",
       "      <td>156.720001</td>\n",
       "      <td>95623200</td>\n",
       "      <td>0.473104</td>\n",
       "      <td>8.152724</td>\n",
       "      <td>34.919440</td>\n",
       "      <td>181.370947</td>\n",
       "      <td>157.619052</td>\n",
       "      <td>-1.831394</td>\n",
       "      <td>-0.373179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-27</th>\n",
       "      <td>155.910004</td>\n",
       "      <td>156.570007</td>\n",
       "      <td>159.789993</td>\n",
       "      <td>155.380005</td>\n",
       "      <td>88063200</td>\n",
       "      <td>6.618480</td>\n",
       "      <td>9.789935</td>\n",
       "      <td>34.683271</td>\n",
       "      <td>180.707184</td>\n",
       "      <td>156.043816</td>\n",
       "      <td>-2.377134</td>\n",
       "      <td>-0.773970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-28</th>\n",
       "      <td>159.250000</td>\n",
       "      <td>163.639999</td>\n",
       "      <td>164.520004</td>\n",
       "      <td>158.929993</td>\n",
       "      <td>130216800</td>\n",
       "      <td>50.365839</td>\n",
       "      <td>19.152474</td>\n",
       "      <td>46.631998</td>\n",
       "      <td>179.335595</td>\n",
       "      <td>156.002403</td>\n",
       "      <td>-2.213630</td>\n",
       "      <td>-1.061902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-29</th>\n",
       "      <td>161.839996</td>\n",
       "      <td>157.649994</td>\n",
       "      <td>166.199997</td>\n",
       "      <td>157.250000</td>\n",
       "      <td>124911916</td>\n",
       "      <td>14.055665</td>\n",
       "      <td>23.679995</td>\n",
       "      <td>39.961846</td>\n",
       "      <td>178.823989</td>\n",
       "      <td>154.818010</td>\n",
       "      <td>-2.538138</td>\n",
       "      <td>-1.357149</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2499 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Open       Close        High         Low     Volume  \\\n",
       "Date                                                                    \n",
       "2012-05-25   17.265854   17.195517   17.304387   17.078696  328507200   \n",
       "2012-05-29   17.458816   17.500711   17.553618   17.287868  380508800   \n",
       "2012-05-30   17.406832   17.711727   17.736804   17.326098  529429600   \n",
       "2012-05-31   17.759736   17.667688   17.782979   17.475944  491674400   \n",
       "2012-06-01   17.405605   17.155756   17.512334   17.141384  520987600   \n",
       "...                ...         ...         ...         ...        ...   \n",
       "2022-04-25  161.119995  162.880005  163.169998  158.460007   96046400   \n",
       "2022-04-26  162.250000  156.800003  162.339996  156.720001   95623200   \n",
       "2022-04-27  155.910004  156.570007  159.789993  155.380005   88063200   \n",
       "2022-04-28  159.250000  163.639999  164.520004  158.929993  130216800   \n",
       "2022-04-29  161.839996  157.649994  166.199997  157.250000  124911916   \n",
       "\n",
       "                   %K         %D        RSI  Bollinger_Upper  Bollinger_Lower  \\\n",
       "Date                                                                            \n",
       "2012-05-25  73.840536  79.791649  44.076190        18.186332        16.302006   \n",
       "2012-05-29  92.212800  81.823858  50.208127        18.132156        16.320371   \n",
       "2012-05-30  98.581578  88.211638  53.966478        18.116348        16.327127   \n",
       "2012-05-31  93.644704  94.813027  53.066230        18.068708        16.349539   \n",
       "2012-06-01  65.424760  85.883681  43.898707        17.991827        16.362718   \n",
       "...               ...        ...        ...              ...              ...   \n",
       "2022-04-25  22.278221  14.362295  41.927588       180.981810       159.888189   \n",
       "2022-04-26   0.473104   8.152724  34.919440       181.370947       157.619052   \n",
       "2022-04-27   6.618480   9.789935  34.683271       180.707184       156.043816   \n",
       "2022-04-28  50.365839  19.152474  46.631998       179.335595       156.002403   \n",
       "2022-04-29  14.055665  23.679995  39.961846       178.823989       154.818010   \n",
       "\n",
       "                MACD    Signal  \n",
       "Date                            \n",
       "2012-05-25 -0.172952 -0.215631  \n",
       "2012-05-29 -0.130183 -0.198541  \n",
       "2012-05-30 -0.078357 -0.174504  \n",
       "2012-05-31 -0.040374 -0.147678  \n",
       "2012-06-01 -0.050992 -0.128341  \n",
       "...              ...       ...  \n",
       "2022-04-25 -1.131611 -0.008625  \n",
       "2022-04-26 -1.831394 -0.373179  \n",
       "2022-04-27 -2.377134 -0.773970  \n",
       "2022-04-28 -2.213630 -1.061902  \n",
       "2022-04-29 -2.538138 -1.357149  \n",
       "\n",
       "[2499 rows x 12 columns]"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recommender</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-05-25</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-05-29</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-05-30</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-05-31</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-06-01</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-25</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-26</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-27</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-28</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-29</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2499 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Recommender\n",
       "Date                   \n",
       "2012-05-25            0\n",
       "2012-05-29            0\n",
       "2012-05-30            0\n",
       "2012-05-31            0\n",
       "2012-06-01            0\n",
       "...                 ...\n",
       "2022-04-25            0\n",
       "2022-04-26            2\n",
       "2022-04-27            0\n",
       "2022-04-28            0\n",
       "2022-04-29            0\n",
       "\n",
       "[2499 rows x 1 columns]"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spliting the data into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1749, 12)\n",
      "(1749, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(750, 12)\n",
      "(750, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Open', 'Close', 'High', 'Low', 'Volume', '%K', '%D', 'RSI',\n",
       "       'Bollinger_Upper', 'Bollinger_Lower', 'MACD', 'Signal'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Open', 'Close', 'High', 'Low', 'Volume', '%K', '%D', 'RSI',\n",
       "       'Bollinger_Upper', 'Bollinger_Lower', 'MACD', 'Signal'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1406\n",
       "1     259\n",
       "2      84\n",
       "Name: Recommender, dtype: int64"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train['Recommender'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    593\n",
       "1    130\n",
       "2     27\n",
       "Name: Recommender, dtype: int64"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test['Recommender'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scaling\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = sscaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RAHUL\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\imblearn\\utils\\_validation.py:299: UserWarning: After over-sampling, the number of samples (1419) in class 2 will be larger than the number of samples in the majority class (class #0 -> 1406)\n",
      "  warnings.warn(\n",
      "C:\\Users\\RAHUL\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\imblearn\\utils\\_validation.py:299: UserWarning: After over-sampling, the number of samples (1419) in class 0 will be larger than the number of samples in the majority class (class #0 -> 1406)\n",
      "  warnings.warn(\n",
      "C:\\Users\\RAHUL\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\imblearn\\utils\\_validation.py:299: UserWarning: After over-sampling, the number of samples (1419) in class 1 will be larger than the number of samples in the majority class (class #0 -> 1406)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from imblearn import under_sampling, over_sampling\n",
    "from imblearn.over_sampling import SMOTE\n",
    "strategy = {2:1419, 0:450, 1:450}\n",
    "#we want Buy and Sell rows to be 2500 and Strong Buy and Strong Sell to be 1500\n",
    "oversample = SMOTE(sampling_strategy=strategy)\n",
    "Xsmote, ysmote = oversample.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4257, 12)\n",
      "(4257, 1)\n"
     ]
    }
   ],
   "source": [
    "print(Xsmote.shape)\n",
    "print(ysmote.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1419\n",
       "2    1419\n",
       "1    1419\n",
       "Name: Recommender, dtype: int64"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ysmote['Recommender'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Data Precision Score : 0.7070353463697489\n",
      "Test Data Recall Score :  0.9081403970667602\n",
      "Test  Data F1 Score:  0.7708747875009058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RAHUL\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\RAHUL\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "#Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#Model Result Analysis\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score, ConfusionMatrixDisplay, precision_score, recall_score, f1_score, classification_report, roc_curve, plot_roc_curve, auc, precision_recall_curve, plot_precision_recall_curve, average_precision_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "#Data Modelling\n",
    "#Logistic Regresion\n",
    "lr = LogisticRegression()\n",
    "lr.fit(Xsmote,ysmote)\n",
    "\n",
    "\n",
    "#Predictions\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "#Precision\n",
    "test_precision = precision_score(y_test, y_pred,  average='macro')\n",
    "print(\"Test Data Precision Score :\", test_precision) \n",
    "#Recall\n",
    "test_recall = recall_score(y_test, y_pred,  average='macro')\n",
    "print(\"Test Data Recall Score : \", test_recall)\n",
    "#F1 Score\n",
    "test_f1 = f1_score(y_test, y_pred,average='macro')\n",
    "print(\"Test  Data F1 Score: \", test_f1)\n",
    "\n",
    "#Storing Results for the Model\n",
    "list_1 = []\n",
    "list_2 = []\n",
    "\n",
    "list_2.append(\"Logistic Regression\")\n",
    "list_2.append((accuracy_score(y_test, y_pred))*100) \n",
    "list_2.append(test_precision)\n",
    "list_2.append(test_recall)\n",
    "list_2.append(test_f1)\n",
    "list_1.append(list_2)\n",
    "list_2 = []\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Data Confusion Matrix :\n",
      "[[558  20  15]\n",
      " [ 19 111   0]\n",
      " [  8   0  19]]\n",
      "Test Data Precision Score : 0.7866659758442426\n",
      "Test Data Recall Score :  0.832842645040509\n",
      "Test  Data F1 Score:  0.8069646511228136\n"
     ]
    }
   ],
   "source": [
    "#Data Modelling\n",
    "#Decision Tree\n",
    "decision_tree = DecisionTreeClassifier()\n",
    "decision_tree.fit(Xsmote,ysmote)\n",
    "\n",
    "\n",
    "#Predictions\n",
    "y_pred = decision_tree.predict(X_test)\n",
    "\n",
    "\n",
    "#Confusion Matrix\n",
    "cm_test = confusion_matrix(y_test, y_pred)  \n",
    "print(\"Test Data Confusion Matrix :\")\n",
    "print(cm_test)\n",
    "#Precision\n",
    "test_precision = precision_score(y_test, y_pred,  average='macro')\n",
    "print(\"Test Data Precision Score :\", test_precision) \n",
    "#Recall\n",
    "test_recall = recall_score(y_test, y_pred,  average='macro')\n",
    "print(\"Test Data Recall Score : \", test_recall)\n",
    "#F1 Score\n",
    "test_f1 = f1_score(y_test, y_pred,average='macro')\n",
    "print(\"Test  Data F1 Score: \", test_f1)\n",
    "\n",
    "\n",
    "list_2.append(\"Decision Tree\")\n",
    "list_2.append((accuracy_score(y_test, y_pred))*100) \n",
    "list_2.append(test_precision)\n",
    "list_2.append(test_recall)\n",
    "list_2.append(test_f1)\n",
    "list_1.append(list_2)\n",
    "list_2 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RAHUL\\AppData\\Local\\Temp/ipykernel_17792/2810810414.py:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  random_forest.fit(Xsmote,ysmote)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Data Confusion Matrix :\n",
      "[[567  14  12]\n",
      " [ 14 116   0]\n",
      " [  4   0  23]]\n",
      "Test Data Precision Score : 0.8395604395604396\n",
      "Test Data Recall Score :  0.9001048958328329\n",
      "Test  Data F1 Score:  0.865630577684907\n"
     ]
    }
   ],
   "source": [
    "#Data Modelling\n",
    "#Random Forest\n",
    "random_forest = RandomForestClassifier()\n",
    "random_forest.fit(Xsmote,ysmote)\n",
    "\n",
    "\n",
    "#Predictions\n",
    "y_pred = random_forest.predict(X_test)\n",
    "\n",
    "\n",
    "#Confusion Matrix\n",
    "cm_test = confusion_matrix(y_test, y_pred)  \n",
    "print(\"Test Data Confusion Matrix :\")\n",
    "print(cm_test)\n",
    "#Precision\n",
    "test_precision = precision_score(y_test, y_pred,  average='macro')\n",
    "print(\"Test Data Precision Score :\", test_precision) \n",
    "#Recall\n",
    "test_recall = recall_score(y_test, y_pred,  average='macro')\n",
    "print(\"Test Data Recall Score : \", test_recall)\n",
    "#F1 Score\n",
    "test_f1 = f1_score(y_test, y_pred,average='macro')\n",
    "print(\"Test  Data F1 Score: \", test_f1)\n",
    "\n",
    "\n",
    "list_2.append(\"Random Forest\")\n",
    "list_2.append((accuracy_score(y_test, y_pred))*100) \n",
    "list_2.append(test_precision)\n",
    "list_2.append(test_recall)\n",
    "list_2.append(test_f1)\n",
    "list_1.append(list_2)\n",
    "list_2 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RAHUL\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Data Confusion Matrix :\n",
      "[[501  58  34]\n",
      " [  5 125   0]\n",
      " [  1   0  26]]\n",
      "Test Data Precision Score : 0.7015197076987745\n",
      "Test Data Recall Score :  0.9231193618489852\n",
      "Test  Data F1 Score:  0.7691107616876044\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "#Data Modelling\n",
    "#Support Vector Machine\n",
    "svc = SVC()\n",
    "svc.fit(Xsmote,ysmote)\n",
    "\n",
    "\n",
    "#Predictions\n",
    "y_pred = svc.predict(X_test)\n",
    "\n",
    "\n",
    "#Confusion Matrix\n",
    "cm_test = confusion_matrix(y_test, y_pred)  \n",
    "print(\"Test Data Confusion Matrix :\")\n",
    "print(cm_test)\n",
    "#Precision\n",
    "test_precision = precision_score(y_test, y_pred,  average='macro')\n",
    "print(\"Test Data Precision Score :\", test_precision) \n",
    "#Recall\n",
    "test_recall = recall_score(y_test, y_pred,  average='macro')\n",
    "print(\"Test Data Recall Score : \", test_recall)\n",
    "#F1 Score\n",
    "test_f1 = f1_score(y_test, y_pred,average='macro')\n",
    "print(\"Test  Data F1 Score: \", test_f1)\n",
    "\n",
    "#Appending Results \n",
    "list_2.append(\"SVM\")\n",
    "list_2.append((accuracy_score(y_test, y_pred))*100) \n",
    "list_2.append(test_precision)\n",
    "list_2.append(test_recall)\n",
    "list_2.append(test_f1)\n",
    "list_1.append(list_2)\n",
    "list_2 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Data Confusion Matrix :\n",
      "[[522  40  31]\n",
      " [  7 123   0]\n",
      " [  2   0  25]]\n",
      "Test Data Precision Score : 0.7280268819600213\n",
      "Test Data Recall Score :  0.9174498621941005\n",
      "Test  Data F1 Score:  0.7902752350053414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RAHUL\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:198: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "#Data Modelling\n",
    "#K Nearest Neighbours\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(Xsmote, ysmote)\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "#Confusion Matrix\n",
    "cm_test = confusion_matrix(y_test, y_pred)  \n",
    "print(\"Test Data Confusion Matrix :\")\n",
    "print(cm_test)\n",
    "#Precision\n",
    "test_precision = precision_score(y_test, y_pred,  average='macro')\n",
    "print(\"Test Data Precision Score :\", test_precision) \n",
    "#Recall\n",
    "test_recall = recall_score(y_test, y_pred,  average='macro')\n",
    "print(\"Test Data Recall Score : \", test_recall)\n",
    "#F1 Score\n",
    "test_f1 = f1_score(y_test, y_pred,average='macro')\n",
    "print(\"Test  Data F1 Score: \", test_f1)\n",
    "\n",
    "#Appending Results \n",
    "list_2.append(\"KNN\")\n",
    "list_2.append((accuracy_score(y_test, y_pred))*100) \n",
    "list_2.append(test_precision)\n",
    "list_2.append(test_recall)\n",
    "list_2.append(test_f1)\n",
    "list_1.append(list_2)\n",
    "list_2 = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Data Confusion Matrix :\n",
      "[[455  87  51]\n",
      " [  5 125   0]\n",
      " [  2   0  25]]\n",
      "Test Data Precision Score : 0.6344728315929905\n",
      "Test Data Recall Score :  0.8849164596775614\n",
      "Test  Data F1 Score:  0.6929967623189427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RAHUL\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "#Data Modelling\n",
    "#Niave Bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(Xsmote, ysmote)\n",
    "y_pred = gnb.predict(X_test)\n",
    "\n",
    "\n",
    "#Confusion Matrix\n",
    "cm_test = confusion_matrix(y_test, y_pred)  \n",
    "print(\"Test Data Confusion Matrix :\")\n",
    "print(cm_test)\n",
    "#Precision\n",
    "test_precision = precision_score(y_test, y_pred,  average='macro')\n",
    "print(\"Test Data Precision Score :\", test_precision) \n",
    "#Recall\n",
    "test_recall = recall_score(y_test, y_pred,  average='macro')\n",
    "print(\"Test Data Recall Score : \", test_recall)\n",
    "#F1 Score\n",
    "test_f1 = f1_score(y_test, y_pred,average='macro')\n",
    "print(\"Test  Data F1 Score: \", test_f1)\n",
    "\n",
    "#Appending Results \n",
    "list_2.append(\"Niave Byaes\")\n",
    "list_2.append((accuracy_score(y_test, y_pred))*100) \n",
    "list_2.append(test_precision)\n",
    "list_2.append(test_recall)\n",
    "list_2.append(test_f1)\n",
    "list_1.append(list_2)\n",
    "list_2 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RAHUL\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1109: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Data Confusion Matrix :\n",
      "[[543  25  25]\n",
      " [ 11 119   0]\n",
      " [  2   0  25]]\n",
      "Test Data Precision Score : 0.7676691979749534\n",
      "Test Data Recall Score :  0.9189978364233564\n",
      "Test  Data F1 Score:  0.8210445002768382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RAHUL\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Data Modelling \n",
    "#Neural Network\n",
    "mlp = MLPClassifier()\n",
    "mlp.fit(Xsmote,ysmote)\n",
    "y_pred = mlp.predict(X_test)\n",
    "\n",
    "\n",
    "#Confusion Matrix\n",
    "cm_test = confusion_matrix(y_test, y_pred)  \n",
    "print(\"Test Data Confusion Matrix :\")\n",
    "print(cm_test)\n",
    "#Precision\n",
    "test_precision = precision_score(y_test, y_pred,  average='macro')\n",
    "print(\"Test Data Precision Score :\", test_precision) \n",
    "#Recall\n",
    "test_recall = recall_score(y_test, y_pred,  average='macro')\n",
    "print(\"Test Data Recall Score : \", test_recall)\n",
    "#F1 Score\n",
    "test_f1 = f1_score(y_test, y_pred,average='macro')\n",
    "print(\"Test  Data F1 Score: \", test_f1)\n",
    "\n",
    "#Appending Results \n",
    "list_2.append(\"NLP\")\n",
    "list_2.append((accuracy_score(y_test, y_pred))*100) \n",
    "list_2.append(test_precision)\n",
    "list_2.append(test_recall)\n",
    "list_2.append(test_f1)\n",
    "list_1.append(list_2)\n",
    "list_2 = []\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>94.133333</td>\n",
       "      <td>0.839560</td>\n",
       "      <td>0.900105</td>\n",
       "      <td>0.865631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NLP</td>\n",
       "      <td>91.600000</td>\n",
       "      <td>0.767669</td>\n",
       "      <td>0.918998</td>\n",
       "      <td>0.821045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>91.733333</td>\n",
       "      <td>0.786666</td>\n",
       "      <td>0.832843</td>\n",
       "      <td>0.806965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KNN</td>\n",
       "      <td>89.333333</td>\n",
       "      <td>0.728027</td>\n",
       "      <td>0.917450</td>\n",
       "      <td>0.790275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>87.600000</td>\n",
       "      <td>0.707035</td>\n",
       "      <td>0.908140</td>\n",
       "      <td>0.770875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVM</td>\n",
       "      <td>86.933333</td>\n",
       "      <td>0.701520</td>\n",
       "      <td>0.923119</td>\n",
       "      <td>0.769111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Niave Byaes</td>\n",
       "      <td>80.666667</td>\n",
       "      <td>0.634473</td>\n",
       "      <td>0.884916</td>\n",
       "      <td>0.692997</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model   Accuracy  Precision    Recall        F1\n",
       "2        Random Forest  94.133333   0.839560  0.900105  0.865631\n",
       "6                  NLP  91.600000   0.767669  0.918998  0.821045\n",
       "1        Decision Tree  91.733333   0.786666  0.832843  0.806965\n",
       "4                  KNN  89.333333   0.728027  0.917450  0.790275\n",
       "0  Logistic Regression  87.600000   0.707035  0.908140  0.770875\n",
       "3                  SVM  86.933333   0.701520  0.923119  0.769111\n",
       "5          Niave Byaes  80.666667   0.634473  0.884916  0.692997"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Displaying all the results from the model\n",
    "model_results = pd.DataFrame(list_1, columns= ['Model', 'Accuracy', 'Precision', 'Recall', 'F1'])\n",
    "model_results.sort_values(by= ['F1'], inplace= True, ascending= False)\n",
    "model_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e9292ea86ddae4deca668d01fcf516d5d89bf271153c9a9a4d4b10b3d781426d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
